{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import Blackjack_QL as bj  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = bj.BlackjackEnv(nb_deck=1, count_cards=False)\n",
    "boost = True\n",
    "Verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning_action(player_hand, usable_ace, dealer_first_card, Q, epsilon):\n",
    "    #epsilon-greedy exploration\n",
    "    if np.random.random() < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    \n",
    "    #Q-Learning optimization\n",
    "    return np.argmax(Q[player_hand - 4, usable_ace, dealer_first_card - 1]) \n",
    "    \n",
    "    \n",
    "def decrease_rate(x):\n",
    "    if x < 0.2:\n",
    "        return 1 - 0.1 * x / 0.2\n",
    "    elif x < 0.6:\n",
    "        return 0.9 - 0.8 * (x - 0.2) / 0.4\n",
    "    elif 0.6 < x < 0.8:\n",
    "        return 0.1 - 0.1 * (x - 0.6) / 0.2\n",
    "    return 0\n",
    "\n",
    "# x = np.linspace(0,1,100)\n",
    "# y = [decrease_rate(el) for el in x]\n",
    "# plt.plot(x, y)\n",
    "# plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "def main(lr=0.1, gamma=0.8, epsilon=0.2, train=False, Q=None, Verbose=False):\n",
    "    avg_win = 0\n",
    "    avg_tie = 0\n",
    "    nb_games = 100000\n",
    "\n",
    "\n",
    "    if train:\n",
    "        #states: 4 to 21 (all the player hands possible); whether the player has a soft ace or not; and dealer's first card out (1 to 10)\n",
    "        #actions: 0 (stand) or 1 (hit)\n",
    "        Q = np.zeros((18, 2, 10, 2))\n",
    "        \n",
    "        if boost:\n",
    "            ###########################################\n",
    "            #IS IT CHEATING TO TELL THIS TO THE AGENT?#\n",
    "            ###########################################\n",
    "            #we want to hit if we have 11 or less\n",
    "            Q[:8, :, :] = [0, 1]\n",
    "            #we want to stand if we have 21\n",
    "            Q[17, :, :] = [1, 0]\n",
    "\n",
    "\n",
    "    #for loop to run nb_games blackjack games\n",
    "    for i_game in range(nb_games):\n",
    "        player_hand, dealer_first_card, usable_ace = env.new_game()\n",
    "        player_hand = bj.sum_hand(player_hand)\n",
    "        usable_ace = (usable_ace) * 1\n",
    "\n",
    "        #theoretically ,there cannot be more than 11 passes (4*aces, 4*two, 3*three)\n",
    "        for t in range(11):\n",
    "            if i_game == 0 and t == 0:\n",
    "                action = env.action_space.sample()\n",
    "            ###########################################\n",
    "            #IS IT CHEATING TO TELL THIS TO THE AGENT?#\n",
    "            ###########################################\n",
    "            elif player_hand <= 11:\n",
    "                action = 1\n",
    "            else:\n",
    "                #epsilon = decrease_rate(i_game / nb_games)\n",
    "                action = q_learning_action(player_hand, usable_ace, dealer_first_card, Q, epsilon)\n",
    "            observation, reward, done, info = env.step(action)\n",
    "            new_player_hand, dealer_first_card, usable_ace = observation\n",
    "            new_player_hand = bj.sum_hand(new_player_hand)\n",
    "            usable_ace = (usable_ace) * 1\n",
    "\n",
    "            if train:\n",
    "                #lr = 0.2 * decrease_rate(i_game / nb_games)\n",
    "                #q_learning update\n",
    "                Q[player_hand - 4, usable_ace, dealer_first_card - 1, action] *= 1 - lr\n",
    "                #Q[player_hand - 4, usable_ace, dealer_first_card - 1, action] += lr * reward   \n",
    "                \n",
    "                ############\n",
    "                #PROBLEM???#\n",
    "                ############\n",
    "                if new_player_hand > 21:\n",
    "                    Q[player_hand - 4, usable_ace, dealer_first_card - 1, action] += lr * reward\n",
    "                    #Q[player_hand - 4, usable_ace, dealer_first_card - 1, 1 - action] += lr * (-reward + gamma)\n",
    "                else:\n",
    "                    Q[player_hand - 4, usable_ace, dealer_first_card - 1, action] += lr * (reward + gamma * np.argmax(Q[new_player_hand - 4, usable_ace, dealer_first_card - 1]))\n",
    "                        \n",
    "\n",
    "            player_hand = new_player_hand\n",
    "\n",
    "            \n",
    "            if Verbose:\n",
    "                print(\"Pass {} - Player's score:\".format(t), player_hand)\n",
    "                if player_hand > 21:\n",
    "                    print(\"Player has been busted.\")\n",
    "\n",
    "\n",
    "            if done:\n",
    "                if Verbose:\n",
    "                    dealer_hand = bj.score(env.dealer)\n",
    "                    print(\"Dealer's score:\", dealer_hand)\n",
    "                    if dealer_hand > 21:\n",
    "                        print(\"Dealer has been busted.\")\n",
    "                \n",
    "                #if the player won the game\n",
    "                if reward == 1.:\n",
    "                    avg_win += 1\n",
    "                    if Verbose:\n",
    "                        print(\"GAME WON\")\n",
    "                        print()\n",
    "                #if there has been a draw\n",
    "                elif reward == 0:\n",
    "                    avg_tie += 1\n",
    "                    if Verbose:\n",
    "                        print(\"TIE\")\n",
    "                        print()\n",
    "                #if the player lost the game\n",
    "                else:\n",
    "                    if Verbose:\n",
    "                        print(\"GAME LOST\")\n",
    "                        print()\n",
    "                break\n",
    "                \n",
    "                \n",
    "        epsilon *= 0.99\n",
    "        lr *= 0.99\n",
    "\n",
    "\n",
    "    if Verbose:\n",
    "        print(\"Average winning score with q-learning:\", 100 * avg_win / nb_games, \"%\")\n",
    "        print(\"Ties:\", 100 * avg_tie / nb_games, \"%  ||  Losses:\", 100 * (1 - (avg_win + avg_tie) / nb_games), \"%\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    if train:\n",
    "        return Q\n",
    "    #percentage of winning games\n",
    "    return round(100 * avg_win / nb_games, 2), round(100 * avg_tie / nb_games, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38.8, 8.12)\n"
     ]
    }
   ],
   "source": [
    "Q_table = main(train=True)\n",
    "print(main(train=False, Q=Q_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38.47, 7.02)\n",
      "(38.75, 8.06)\n",
      "(39.29, 8.41)\n",
      "(39.03, 8.23)\n",
      "(38.4, 7.73)\n",
      "(40.27, 8.0)\n",
      "(41.22, 8.02)\n",
      "(39.8, 7.56)\n",
      "(40.67, 8.95)\n",
      "(41.31, 6.67)\n"
     ]
    }
   ],
   "source": [
    "lst = [1, 0.5, 0.3, 0.2, 0.1, 1e-2, 1e-3, 1e-5, 1e-10, 0]\n",
    "\n",
    "for lr in lst:\n",
    "    Q_table = main(train=True, lr=lr)\n",
    "    print(main(train=False, Q=Q_table, lr=lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing different discount rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38.81, 7.74)\n",
      "(39.97, 8.13)\n",
      "(38.32, 7.42)\n",
      "(39.32, 7.44)\n",
      "(40.93, 8.38)\n",
      "(39.85, 7.66)\n",
      "(39.12, 7.8)\n",
      "(39.45, 8.32)\n",
      "(39.77, 7.98)\n",
      "(39.3, 8.05)\n"
     ]
    }
   ],
   "source": [
    "lst = [1, 0.5, 0.3, 0.2, 0.1, 1e-2, 1e-3, 1e-5, 1e-10, 0]\n",
    "\n",
    "for gamma in lst:\n",
    "    Q_table = main(train=True, gamma=gamma)\n",
    "    print(main(train=False, Q=Q_table, gamma=gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing different exploration rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40.21, 8.22)\n",
      "(39.59, 8.02)\n",
      "(38.6, 7.27)\n",
      "(39.81, 7.82)\n",
      "(36.02, 7.21)\n",
      "(39.13, 7.23)\n",
      "(38.3, 7.52)\n",
      "(39.05, 7.41)\n",
      "(38.74, 7.35)\n",
      "(38.47, 7.71)\n"
     ]
    }
   ],
   "source": [
    "lst = [1, 0.5, 0.3, 0.2, 0.1, 1e-2, 1e-3, 1e-5, 1e-10, 0]\n",
    "\n",
    "for epsilon in lst:\n",
    "    Q_table = main(train=True, epsilon=epsilon)\n",
    "    print(main(train=False, Q=Q_table, epsilon=epsilon))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr = 1 || gamma = 1 || epsilon = 1\n",
      "(39.18, 7.67)\n",
      "lr = 1 || gamma = 1 || epsilon = 0.5\n",
      "(37.33, 7.91)\n",
      "lr = 1 || gamma = 1 || epsilon = 0.3\n",
      "(37.75, 7.29)\n",
      "lr = 1 || gamma = 1 || epsilon = 0.2\n",
      "(36.8, 7.89)\n",
      "lr = 1 || gamma = 1 || epsilon = 0.1\n",
      "(36.55, 7.24)\n",
      "lr = 1 || gamma = 1 || epsilon = 0.01\n",
      "(38.37, 7.61)\n",
      "lr = 1 || gamma = 1 || epsilon = 0.001\n",
      "(38.29, 7.99)\n",
      "lr = 1 || gamma = 1 || epsilon = 1e-05\n",
      "(37.51, 7.28)\n",
      "lr = 1 || gamma = 1 || epsilon = 1e-10\n",
      "(37.72, 7.51)\n",
      "lr = 1 || gamma = 1 || epsilon = 0\n",
      "(38.52, 8.03)\n",
      "lr = 1 || gamma = 0.5 || epsilon = 1\n",
      "(40.21, 7.17)\n",
      "lr = 1 || gamma = 0.5 || epsilon = 0.5\n",
      "(39.15, 7.66)\n",
      "lr = 1 || gamma = 0.5 || epsilon = 0.3\n",
      "(36.89, 7.32)\n",
      "lr = 1 || gamma = 0.5 || epsilon = 0.2\n",
      "(40.08, 8.06)\n",
      "lr = 1 || gamma = 0.5 || epsilon = 0.1\n",
      "(37.6, 7.08)\n",
      "lr = 1 || gamma = 0.5 || epsilon = 0.01\n",
      "(37.77, 7.86)\n",
      "lr = 1 || gamma = 0.5 || epsilon = 0.001\n",
      "(36.28, 6.77)\n",
      "lr = 1 || gamma = 0.5 || epsilon = 1e-05\n",
      "(36.28, 7.21)\n",
      "lr = 1 || gamma = 0.5 || epsilon = 1e-10\n",
      "(36.85, 7.44)\n"
     ]
    }
   ],
   "source": [
    "lst = [1, 0.5, 0.3, 0.2, 0.1, 1e-2, 1e-3, 1e-5, 1e-10, 0]\n",
    "\n",
    "results = np.zeros((10, 10, 10))\n",
    "\n",
    "for i, lr in enumerate(lst):\n",
    "    for j, gamma in enumerate(lst):\n",
    "        for k, epsilon in enumerate(lst):\n",
    "            Q_table = main(train=True, lr=lr, gamma=gamma, epsilon=epsilon)\n",
    "            result = main(train=False, Q=Q_table, lr=lr, gamma=gamma, epsilon=epsilon)\n",
    "            results[i, j, k] = result[0]\n",
    "            print(\"lr = \" + str(lr) + \" || gamma = \" + str(gamma) + \" || epsilon = \" + str(epsilon))\n",
    "            print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To print the Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = [i for i in range (2, 11)]\n",
    "cards.append(1)\n",
    "\n",
    "dealer_first_cards = [str(i) + \"\" for i in cards]\n",
    "dealer_first_cards[-2] += \" or any face\"\n",
    "dealer_first_cards[-1] = \"ace\"\n",
    "player_cards = [str(i) for i in range(4, 22)]\n",
    "\n",
    "\n",
    "combinations = []\n",
    "for i in range(4, 22):\n",
    "    lst = []\n",
    "    for k in cards:\n",
    "        pair = []\n",
    "        if np.argmax(Q_table[i - 4, 0, k - 1]) == 0:\n",
    "            pair.append(\"STAND\")\n",
    "        else:\n",
    "            pair.append(\"HIT\")\n",
    "            \n",
    "        if np.argmax(Q_table[i - 4, 1, k - 1]) == 0:\n",
    "            pair.append(\"STAND\")\n",
    "        else:\n",
    "            pair.append(\"HIT\")\n",
    "        lst.append(pair)\n",
    "    combinations.append(lst)\n",
    "\n",
    "combinations = np.array(combinations)\n",
    "print(\"With a soft ace\")\n",
    "print(DataFrame(np.array(combinations[:, :, 0]), player_cards, dealer_first_cards))  #begins at 13\n",
    "print(\"With a hard ace\")\n",
    "print(DataFrame(np.array(combinations[:, :, 1]), player_cards, dealer_first_cards))  #begins at 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To print Normal Play Strategy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Normal Play Q-table\n",
    "Q_normal_play = np.zeros((18, 2, 10, 2))\n",
    "Q_normal_play[:8, :, :] = [0, 1]\n",
    "Q_normal_play[8, 0, 0:3] = [0, 1]\n",
    "Q_normal_play[8, 0, 3:6] = [1, 0]\n",
    "Q_normal_play[8, 0, 6:] = [0, 1]\n",
    "Q_normal_play[9:13, 0, 0] = [0, 1]\n",
    "Q_normal_play[9:13, 0, 1:6] = [1, 0]\n",
    "Q_normal_play[9:13, 0, 6:] = [0, 1]\n",
    "Q_normal_play[13:, 0, :] = [1, 0]\n",
    "Q_normal_play[8, 1, :] = [0, 1]\n",
    "Q_normal_play[9:14, 1, :] = [0, 1]\n",
    "Q_normal_play[14, 1, 0] = [0, 1]\n",
    "Q_normal_play[14, 1, 1:8] = [1, 0]\n",
    "Q_normal_play[14, 1, 8:] = [0, 1]\n",
    "Q_normal_play[15:, 1, :] = [1, 0]\n",
    "\n",
    "# list_i = [i for i in range(1, 11)]\n",
    "# list_j = [i for i in range(4, 22)]\n",
    "# print(\"Hard Ace case\")\n",
    "# print(DataFrame(Q_normal_play[:, 0, :, 0], list_j, list_i))\n",
    "# print(\"Soft Ace case\")\n",
    "# print(DataFrame(Q_normal_play[:, 1, :, 0], list_j, list_i))\n",
    "\n",
    "\n",
    "print(main(train=False, Q=Q_normal_play))\n",
    "\n",
    "\n",
    "err = 0\n",
    "for i in range(18):\n",
    "    for j in range(2):\n",
    "        for k in range(10):\n",
    "            if np.argmax(Q_table[i, j, k]) != np.argmax(Q_normal_play[i, j, k]):\n",
    "                err += 1\n",
    "err /= 3.6\n",
    "print(str(err) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To print Normal Play strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations_normal_play = []\n",
    "for i in range(4, 22):\n",
    "    lst = []\n",
    "    for k in cards:\n",
    "        pair = []\n",
    "        if np.argmax(Q_normal_play[i - 4, 0, k - 1]) == 0.:\n",
    "            pair.append(\"STAND\")\n",
    "        else:\n",
    "            pair.append(\"HIT\")\n",
    "            \n",
    "        if np.argmax(Q_normal_play[i - 4, 1, k - 1]) == 0.:\n",
    "            pair.append(\"STAND\")\n",
    "        else:\n",
    "            pair.append(\"HIT\")\n",
    "        lst.append(pair)\n",
    "    combinations_normal_play.append(lst)\n",
    "\n",
    "combinations_normal_play = np.array(combinations_normal_play)\n",
    "print(\"With a soft ace\")\n",
    "print(DataFrame(np.array(combinations_normal_play[:, :, 0]), player_cards, dealer_first_cards))  #begins at 13\n",
    "print(\"With a hard ace\")\n",
    "print(DataFrame(np.array(combinations_normal_play[:, :, 1]), player_cards, dealer_first_cards))  #begins at 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To run several batches with different learning rate / gamma / epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [1, 0.5, 0.1, 1e-3, 1e-5, 1e-10, 0]\n",
    "gamma_list = [1, 0.8, 0.5, 0.3, 0.1, 1e-3, 0]\n",
    "epsilon_list = [0.5, 0.3, 0.2, 0.1, 1e-3, 0]\n",
    "\n",
    "\n",
    "results = np.zeros((7, 7, 7))\n",
    "\n",
    "for i in range(7):\n",
    "    for j in range(7):\n",
    "        print(\"Gamma = \" + str(gamma_list[j]))\n",
    "        for k in range(6):\n",
    "            result = main(train=True, lr=lr_list[i], gamma=gamma_list[j], epsilon=epsilon_list[k])\n",
    "            print(result)\n",
    "            results[i, j, k] = result\n",
    "\n",
    "indices = np.argmax(results)\n",
    "print(indices)\n",
    "print(\"Average winning score with q-learning:\", results[indices], \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}